{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 104397\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n",
      "Traffic Sign number: 4\n",
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.895\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.903\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.945\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "Model saved\n",
      "Test Accuracy = 0.933\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEl9JREFUeJztnFmMJVd5x3+nqu6+dd/ex9OzeDw2XrFjh0UkEVJAAvJA\nEAKFB7IokvOClEh5CEpe8kikkNdIkJDkIVIUiUghBBIQsmOIBMLgDXvGMz3unume6b1v911rP3n4\nvtseHI/nenooW8z9pFH11D11zqnv/M+3nzLWWsaUDTnv9ATuJBozO0MaMztDGjM7QxozO0MaMztD\nGjM7QzoSs40xHzPGvGqMWTLGfPF2TeqXlcytOjXGGBe4AHwUWAN+DHzOWvvK7ZveLxd5R3j2fcCS\ntfY1AGPMvwCfBG7I7FK5bmsTs5SrDYyT/txvSRTItd/hoLUDQIS2cQyOkwOgXJkEoNaYkt+MhVTa\nhf0DAA7aO+QLdQAq2t4tFKUrB8xwUJvIOH4HgM7BDnEqv07Up6XPOMTNydhOIu0PBn3pe2KSgnHZ\n216n29k/7PZGdBRm3wWsXvf/NeD9b2xkjHkSeBKg2pjh009+mV/9wMfxyr42EEa1N5YB2H/uab71\n9b8DYD2Vl0orBarVGQAef+IzAPz6Jz4PgOtZkl5bJvDStwH4z2//I6fu+SgAT3zgUwA0T94HQKli\nybny2nHYAmD7wtMAPPXNf2Cvlwfgtz72BwCsbq/RmJ+TZzuymN9+/qcAfPCTn+ZMoclf/cXvjsSw\nozD7zVby/8kka+1XgK8AzM3dbQv7HQ7WVpi/Z0Z7EbS4PWH+dH2OUqkiz3a60qY/YJDuA5Bo+ySW\nhcCP2FmWhdpb25BbbhVn/iwAO7ag7UIA5it5vFSm6VgZZyp/CoBKlOdAXyHqy3hef5fBagxAqyU7\nIOjKIkWDFr71sOnP79Ib0VGYvQYsXvf/48C1txzMSZmuRmy0X6JhPwxAwcgU+o4wpVGqUS7Jlmdf\nXtKmDoVqGQA3kvZ5X5i+snqBSPnu5ZsALM6e5L5TdwHgWxFP5bw856bgWGF8Ekof/ZZcSTxMfkLa\nT9wLwLxXxk3l2asdWVRPcWYHHm5+dBYexRr5MXDWGHPaGJMHfgf4xhH6+6WnW0a2tTY2xnwB+G/A\nBb5mrX35LR9yU5xal8utLRYGvwbAZL4EQOLJlu4FIdjhNperydeYqN0PQMUR8dPZka3cbW+xcOy9\nAKyurwFw5tjDnJwSZOcnRd5aR/oKux263csARL5s/6AjWyOyLolyJCnLH1MTj1CMRFbvbZ4HIPVl\n7CsXr1KarRCFv3gxgrX2W8C3jtLHnURHYvbbpdQr0p85y0yuh90TQ8bmRTF2X1uR/w8sXkHkt3VF\nyrm1CRbuOgWAk4qSWt58FYC842NblwDobcm1eNcU55deAMCooIyNC0DOm2CuKbup0ZgFYPK0yOn8\n82VCX2T8ri8WTqlSZnf9gtzbuSjvoabi1ZV1ZiYeILY3tfpk7iO1GtNtoUyRHVuPnXieRglWV54D\nYMcRtGy1ZN3vPfYbeM2GPHBVEJMrF2lOiv1r+kvyk5pj1h+wtCUmX29XnKHBRUgc6c9xdfC8WDPN\nuQfonXkUgJkzYvUcd8Q6yZmINIik31iu2A221sVPy6eyC91I2leqNe5/5EG+UyqN9P6ZMjuJfXY3\nzjE1WWcQyIuudasANOZPA1CZnyVXl3teXjllA9otUWq714Sxy+09AOLeHjn16IiUUYkFIwtlHN3i\n6sh01la5/OqzAJQXTwDw/jNiwXbbm5CIQp2dOA5AGixxfPExACZmRBG/vPpVAGbmStQnAhx3NAU5\nFiMZUqbIJk5hz+fEPY/hNAWhL5x/DQCnIOgoNfIUSiIyymXZ+vGgx8rF5wFId0Vx2b54l04SEqvX\n5xw6tdcprGR4la1P6JP2xDvs7Yup+OPLEkdJHJf6oijNgjpZ2zsDirYGwEDFSOwJ28qNKkUDzmj6\ncYzsLClbZDsepjLBmg+nG4KS+ZpAbzMQR8HalJw6OhVPEB50A/z2rvShptkwaGjdHJ6697lhZK9Q\nOAzS2FT6t4E8Fw8CnFADXP0BAJ1ArhSalKdlXq+++hIAd999An97G4AXll4EoK195gtFvG4fk2Tg\n1LxdcgippqusXlujbu8BYHNdtvd6KFv74ROQUzfO9jXsenBA6ov14eqedTVYVZ2apzypYVQNhVrX\n5TBOr4whHXqQfeL+JgC9PWFiHMgcbLDD7upPALg8K7b3qTOfZU50JUvnZMETK3PpRzEvri4zCMMR\n339MmVGmyDaxT751no22odcQZO93BNGtfUHgxvIV9q5cBSBq9+RBP8JTgzlfF9Os0hRFVpxokKhZ\np3F/Uptgh0rTlZupeqPeRIFcRcSNWxAFfLAlijLqBSRtQf3aBUH4a2ce4j33SyJhYlqUZm5Z+t7a\nucYg18RPR8t2jZGdIWWK7GKpzNn7HyfdaFGvzwPw0CMPAuA/80MAll7+EStXJG4cDYLDaebL4lWW\nFdG5hsSuIwOpKiiraa6UGMeRV0s0tRaGqgTTw3wFBU191Y0g8+DqGkmg5t32FQAuvvB9ktIDck93\nS0GdrYOVF/FbXeJBb6T3HyM7Q8rW9HMruJPvo7G7zmBTNPvJY4LUi0YQtfTKU/RaWwBYRWyaK1Gb\nVJOgKObgzp44RWFgSdXiCGNBry24NCcl7p1LZXesb0oSKQlicir/i01p06xI8rjc7NPfEpmd+OI0\nHVz9GddeE9l+15RYPVaT02F3hZNzFXJONNLrZxsbSVN2e13O3r3Aiy98E4C56YcBuGv6DADLr1zA\nBEPxoUqxVqMwIabeXlsWYm1NtnnBq5D3xOTrq6gI+4ZKReIrB3sSnAoDWbh6aRpSSQbs7MqC5T2J\ny9RqTXL7Ej5lIIvf297B3xLxUZuRWIoXy7z8sMjGtcHIyYOxGMmQsjX9SCiZDrvxLhs5MfnWEVSW\nyuJEuElw6JE5joiMQrmO46opp66jVxbzbX76GAU167ZaEgns+32cVByNUPFULEn8Y3p+DhuLCReu\nickX9AXFk7N1CiXZEaF6l0QRni9/V1WRllxBdteEtLGH4Zeb0RjZGVKmyM55DrPTJVrdXZpFkcH9\nDYmJVENxgePkddfXdQWBhVIdo5G2UlUQOucK6ivlBuFAlJmvaKw1JqgU5PcDTQa4Ddk5FFw8fTan\n11grnRInd1g5ZTUe7tgIAq3QGoi+SDUUMNEsc+LkSdaey4/0/tmKEcfFK06SBgk5hNlXXhElVTyQ\nOEUYJ6C2sdW8ISaHNSJuCkWxCPJ5YZCxCd1Qw65WnitXJsnpo3ntK0IXE4ec2uCeioNBOhzPHCYZ\nhh4o1mJjeTbVq9VFmjn+IR5//CM8853RKjjGYiRDyhTZUZyyudunX5hl4bTY18Gm2LXtlnhhyfVx\nf/UIrY2waJXUMDEwRH0c0u+oB6dRv0KpjHHEfDRqU8eJopKU1MprO6qch2FYLIfRwsMQLUjxJhD4\nwzlKn5OLJykem8HJjcbGMbIzpGzrRuKE/s4+19IexycEVUki5tfAiqJMXRc7rKUbmm9Bj3wiXtxQ\nUQ4RGIcR/kCUoFeV+InrOTj6ao4qyjRRLy8BZ4hsha+jRZrG75OqQzX8LXQdbEHm2uuIbtjTBEZU\nK2Kc5M1LTN+EbopsY8yiMeYpY8w5Y8zLxpg/1vtNY8x3jTEX9To52pB3Lo2C7Bj4U2vtT40xNeAn\nxpjvAr8PfM9a+yU94vFF4M/eqqN8Psfi8WP4S6/SXpZYRTyQOpCDtrjfifFIhmVMisaw14ZJiV9Y\n/WloebQ7HaJEYNioSWLWcV5v6KlZYtVx8Ts+jifPdhJBdFHr+tK4j69m5FBqe14OT3XBVkscsYFW\ntTqlKqktY0eUxjdltrV2HVjXvzvGmHNIIfwngQ9rs38CnuYmzHYcl3K9xoOzTf7ne08B0G1rTbUv\nL544eRIVFY6mm8JOm7AnWzfnaWmaipi+v39oipVLwmzjOjjKgFpNPML9nsQ89rdeY1+DU4nmOMta\nahz6XaJwGC5Vz7NYByvPbu2LqMuVTwIw0ZjCmJGlyNtTkMaYU8BjwI+AOV2I4YLM3uCZJ40xzxpj\nnu1oYc2dSiMrSGNMFfg68CfW2rYxo63n9ScPTp99xCapoTsYsNuREOvlDUF2uyPoyZnKoVIbihEb\nDuhtrwNQ1ziIU1STzkJFRUwhL6h3DIcVlZWaKM1Fne6g24VE2nmaNM5rdLG/0wItLSMnpmZpsk6s\nIdTA14qA43cDMFluMiofYERkG2NyCKP/2Vr7b3p70xizoL8vAFsjj3qH0k2RbWTp/h44Z639m+t+\n+gbwe8CX9PrvN+srCSNaq1f54blzNI+L1ImSYwC09qXQ3LgB5aIgL1WUWd8n7MoO6GwKPqrTkvhd\nmD1BqnI851xfRK+1fhpfqTUkBVarTh8G/6OgrX2uABB3OrjqrhfqgnpTNMR5UZCpV9Ux5QhIJVfG\nNaPFsmE0MfIh4PPAS8aY5/XenyNM/ldjzB8CV4DPjDzqHUqjWCM/4MYK9zffzmC97j7PPvMf5I9P\n89i9Hwfg+Y5o+MvFFQDanQGFiqCqoqbcIAkOg0GRlhq0I7EaKrMLFGtaCTU8BWZSjMphoybi8ERX\n7FuinkTxei3ZLUFbEO7i4BQFvbWmZGXSYpNyUxyqjTUx/aZnREfkSfQM5milDNnmIG1KEvVZKE9R\ndGXCxtFSM1UfvTQhCER5NqfFJMsXmnR2hCHDlFnaF+Z31kLcsjAvV5G+nEIOT806q6Io1ueiro8N\n9JiflqENa1LcUp3GgqTnJmckVTawRdxEFGOkJmlNme++HhscicaxkQwp48JKB6daIZ9rsLoi51/2\n90SM+OoFhklEVcXC4vt/Re7tdnGWpBi+uyUoThSpNuqSHIjXF3Q0buI4OHrywFUJOMzAkySHosVR\nxVouy44o12aYmpYsvh2eh/Qq+D3xbt2KOk0VZZvRiOGI8B4jO0PK9kxNHLO1u0m5cQlzcA6A/pbE\nRvp9UXhx4pAaMdPcusjNB07NMtuUnbD0khhEvX2R6/12i0ijcEaVoElf/3jA8CBXMqz9yzu4eUmt\neVr9mmrcvJOk5LXdfScE4UF3wPJlcbgKWoXlFocKOQW//Xql7E0o2xBrMsDvnOfS8hYffVAO7nfP\naRJAxYjBAysvVSnIC88eW6TiiaIbni5otSXfeLB1le6uiJje8Kx7/HrJ8CGT1fNsNOvUpsRObpyW\n4s7gQAo5L5xf5tii2O9T07JYG7vr9HsChNqCHHwtqodbAPp7XWwyGrPHYiRDyhTZ+ZzH8blpdnsB\n3b6gwzeazdY2OcfFiTU8ajVGYkoUXDG3TmpVUn1W/j/z3ie49NJ/AfDKJTmfM1mYZHtHFOlGX8y7\nQBMG7zn1OI8/+kHpvyj3/vf7IspSP6SmIVlHk8i9g8vEmvmfm5Kxi2pWmqBNf+cyaTwuhn/XUabI\ndvN1mic/QnjpEkvLgoYdPayfaozBOFCrSpQtHYi3ePF8yrQqyzgvpuJAI3HN02cIQ1Ge63vSfrE5\nR68n4dxgV5AdulKiTPEJBupdtpbl4GtZxy4kPQI1I/e13GFzfxsnLw7YvbMS7Qv2RIZf6V9ke+MH\nhNEw4fDWNEZ2hpTxceqYnWCT06c8XvzJ9wHY80W2otmW1FrS4XkNdZNzTh9XwiV0XdH8e3vicrcT\nF1MT66Wg7nS1VKSqJ8hKnqv9innYG1xm40CsiuMLDwFg+lqiHMUMdD7XtsSR2W7vQkVi4lFLrJYA\nLQry9qlPVXG925QWu52UJiGdg2vsuPHhVxIi1YwxQzHi0A/0NFYiL/Hw2fso6Qe2pkI1u0JZEC82\nON6w/EtPkjkeeQ2LusMz7Bqkmpuuc/+9ctqh6IqoOfecLFw/Bb+gRZPrYk4GaUq+LCvd0mDYmRnx\nA+L2LlthJHb9CDQWIxnSLX/X75YGM2Yb6AE7mQ166zTN6PM8aa2duVmjTJkNYIx51lr7RKaD3gL9\nIuY5FiMZ0pjZGdI7weyvvANj3grd9nlmLrPvZBqLkQwpM2a/m7+1/RaVun9pjLlqjHle/33iSONk\nIUbe7d/a1oquhesrdYHfBj4LdK21f307xskK2Yff2rbWhsDwW9vvCrLWrltrf6p/d4Bhpe5tpayY\n/Wbf2r7tL3M76A2VugBfMMa8aIz52lEL/rNi9kjf2n6n6Y2VusDfAmeAR5Ea9S8fpf+smP22v7Wd\nNb1Zpa61dtNam1g55vBVRBzeMmXF7Hf1t7ZvVKk7LIlW+hTws6OMk0k8+5a+tZ0t3ahS93PGmEcR\nkbcC/NFRBhl7kBnS2IPMkMbMzpDGzM6QxszOkMbMzpDGzM6QxszOkMbMzpD+D1ckgqe9X16UAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f540cf18710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = \"train.p\"\n",
    "validation_file= \"valid.p\"\n",
    "testing_file = \"test.p\"\n",
    "signnames = pd.read_csv('signnames.csv')\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def rotateImage(image, angle):\n",
    "\n",
    "    rows,cols,colors = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    dst = cv2.warpAffine(image.squeeze(),M,(cols,rows))\n",
    "    return dst\n",
    "\n",
    "e = 0\n",
    "\n",
    "size_train = len(X_train)\n",
    "\n",
    "temp_x_train = X_train.copy()\n",
    "temp_y_train = y_train.copy()\n",
    "temp_x_train_2 = X_train.copy()\n",
    "temp_y_train_2 = y_train.copy()\n",
    "\n",
    "for e in range(size_train):\n",
    "    temp_x_train[e] = rotateImage(X_train[e], 5)\n",
    "    temp_y_train[e] = y_train[e]\n",
    "    temp_x_train_2[e] = rotateImage(X_train[e], -5)\n",
    "    temp_y_train_2[e] = y_train[e]\n",
    "    #grey_scale_x[e] = cv2.cvtColor(X_train[e], cv2.COLOR_BGR2GRAY)\n",
    "    #grey_scale_y[e] = y_train[e]\n",
    "\n",
    "X_train = np.concatenate((X_train, temp_x_train), axis=0)\n",
    "y_train = np.concatenate((y_train, temp_y_train), axis=0)\n",
    "\n",
    "X_train = np.concatenate((X_train, temp_x_train_2), axis=0)\n",
    "y_train = np.concatenate((y_train, temp_y_train_2), axis=0)\n",
    "\n",
    "#X_train = np.concatenate((X_train, grey_scale_x), axis=0)\n",
    "#y_train = np.concatenate((y_train, grey_scale_y), axis=0)\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.5, random_state=0)\n",
    "\n",
    "#print(\"Update Image Shape: {}\".format(X_train[0].shape))\n",
    "\n",
    "## Step 1\n",
    "\n",
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = signnames.shape[0]\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "\n",
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(\"Traffic Sign number:\", y_train[index])\n",
    "\n",
    "## Step 2\n",
    "\n",
    "### Preprocess the data here. Preprocessing steps could include normalization, converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "    \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    \n",
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    #sigma = 0.1\n",
    "    sigma = 0.05\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # Dropout for L1\n",
    "    #conv1 = tf.nn.dropout(conv1, 0.99)     \n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # Dropout for L2\n",
    "    #conv2 = tf.nn.dropout(conv2, 0.90)    \n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Dropout for L3\n",
    "    fc1 = tf.nn.dropout(fc1, 0.99)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    \n",
    "    # Dropout L4\n",
    "    #fc2 = tf.nn.dropout(fc2, 0.99)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(n_classes))\n",
    "    \n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits\n",
    "\n",
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)\n",
    "\n",
    "#rate = 0.001\n",
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})   \n",
    "        \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    \n",
    "## Step 3\n",
    "\n",
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "##index = random.randint(0, len(X_train))\n",
    "##image2 = X_train[index].squeeze()\n",
    "\n",
    "##plt.figure(figsize=(1,64))\n",
    "##plt.imshow(image2)\n",
    "##print(\"Traffic Sign number:\", y_train[index])\n",
    "\n",
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
